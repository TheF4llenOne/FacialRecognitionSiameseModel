{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import uuid library to generate unique image names\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the directories\n",
    "os.makedirs(POS_PATH, exist_ok=True)\n",
    "os.makedirs(NEG_PATH, exist_ok=True)\n",
    "os.makedirs(ANC_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lfw/Vladimir_Putin/Vladimir_Putin_0008.jpg: Can't unlink already-existing object\n",
      "tar: Error exit delayed from previous errors.\n"
     ]
    }
   ],
   "source": [
    "# http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "# Uncompress Tar GZ Labelled Faces in the Wild Dataset\n",
    "!tar -xf lfw.tgz\n",
    "\n",
    "# Move LFW Images to the following repository data/negative\n",
    "for directory in os.listdir('lfw'):\n",
    "    for file in os.listdir(os.path.join('lfw', directory)):\n",
    "        EX_PATH = os.path.join('lfw', directory, file)\n",
    "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
    "        os.replace(EX_PATH, NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data\\\\anchor\\\\4b163aca-82c9-11ef-95cc-04421a97446c.jpg'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "   \n",
    "    # Cut down frame to 250x250px\n",
    "    frame = frame[120:120+250,200:200+250, :]\n",
    "    \n",
    "    # Collect anchors \n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        # Create the unique file path \n",
    "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out anchor image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # Collect positives\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        # Create the unique file path \n",
    "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out positive image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # Show image back to screen\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    \n",
    "    # Breaking gracefully\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Release the webcam\n",
    "cap.release()\n",
    "# Close the image show frame\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21cbfda2c40>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(frame[120:120+250,200:200+250, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug(img):\n",
    "    data = []\n",
    "    for i in range(9):\n",
    "        img = tf.image.stateless_random_brightness(img, max_delta=0.02, seed=(1,2))\n",
    "        img = tf.image.stateless_random_contrast(img, lower=0.6, upper=1, seed=(1,3))\n",
    "        # img = tf.image.stateless_random_crop(img, size=(20,20,3), seed=(1,2))\n",
    "        img = tf.image.stateless_random_flip_left_right(img, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_jpeg_quality(img, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_saturation(img, lower=0.9,upper=1, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "            \n",
    "        data.append(img)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(ANC_PATH, '6bb81fcc-82ab-11ef-91e3-04421a97446c.jpg')\n",
    "img = cv2.imread(img_path)\n",
    "augmented_images = data_aug(img)\n",
    "\n",
    "for image in augmented_images:\n",
    "    cv2.imwrite(os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(os.path.join(POS_PATH)):\n",
    "    img_path = os.path.join(POS_PATH, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    augmented_images = data_aug(img) \n",
    "    \n",
    "    for image in augmented_images:\n",
    "        cv2.imwrite(os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(3000)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(3000)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_test = anchor.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'data\\\\anchor\\\\8aa2c64f-82ab-11ef-9634-04421a97446c.jpg'\n"
     ]
    }
   ],
   "source": [
    "print(dir_test.next())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing - Scale and Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    \n",
    "    # Read in image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    # Load in the image \n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    \n",
    "    # Preprocessing steps - resizing the image to be 100x100x3\n",
    "    img = tf.image.resize(img, (100,100))\n",
    "    # Scale image to be between 0 and 1 \n",
    "    img = img / 255.0\n",
    "\n",
    "    # Return image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess('data\\\\anchor\\\\6bb81fcc-82ab-11ef-91e3-04421a97446c.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012254902"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'data\\\\anchor\\\\686f85d3-82ab-11ef-8ecc-04421a97446c.jpg',\n",
       " b'data\\\\positive\\\\52007ec8-82c9-11ef-b665-04421a97446c.jpg',\n",
       " 1.0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = preprocess_twin(*example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21cc3c6c700>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataloader pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training partition\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing partition\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Architecture and Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base network\n",
    "def create_base_network():\n",
    "    inputs = Input(shape=(100,100,3), name='input_image')\n",
    "\n",
    "    # Layer 1\n",
    "    conv1 = Conv2D(64, (10, 10), activation='relu')(inputs)\n",
    "    pool1 = MaxPooling2D(64, (2,2), padding='same')(conv1)\n",
    "\n",
    "    # Layer 2\n",
    "    conv2 = Conv2D(128, (7, 7), activation='relu')(pool1)\n",
    "    pool2 = MaxPooling2D(64, (2,2), padding='same')(conv2)\n",
    "\n",
    "    # Layer 3\n",
    "    conv3 = Conv2D(128, (4, 4), activation='relu')(pool2)\n",
    "    pool3 = MaxPooling2D(64, (2,2), padding='same')(conv3)\n",
    "\n",
    "    # Layer 4\n",
    "    conv4 = Conv2D(256, (4, 4), activation='relu')(pool3)\n",
    "    \n",
    "    # Flatten the output of the last convolutional layer\n",
    "    flat = Flatten()(conv4)\n",
    "\n",
    "    # Fully connected layer\n",
    "    dense1 = Dense(4096, activation='sigmoid')(flat)\n",
    "    drop = Dropout(0.2)(dense1) \n",
    "\n",
    "    # Define the base model\n",
    "    base_network = Model(inputs=inputs, outputs=dense1)\n",
    "    base_network.summary()\n",
    "\n",
    "    return Model(inputs=inputs, outputs=drop, name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_image (InputLayer)    [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 91, 91, 64)        19264     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 46, 46, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 40, 40, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 20, 20, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 17, 17, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 6, 6, 256)         524544    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4096)              37752832  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,960,448\n",
      "Trainable params: 38,960,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the base network\n",
    "base_network = create_base_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model(base_network):\n",
    "    # Define the inputs for the Siamese Network\n",
    "    input_a = Input(name='input_img', shape=(100, 100, 3))\n",
    "    input_b = Input(name='validation_img', shape=(100, 100, 3))\n",
    "\n",
    "    # Process both inputs using the shared base network\n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "\n",
    "    # Define a Lambda layer for computing the absolute difference between the two embeddings\n",
    "    # This will serve as the similarity measure between the two inputs\n",
    "    distance = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))([processed_a, processed_b])\n",
    "\n",
    "    # Define the fully connected layers and output layer for similarity scoring\n",
    "    classifier = Dense(1, activation='sigmoid')(distance)\n",
    "    \n",
    "    # Create the Siamese model\n",
    "    model = Model(inputs=[input_a, input_b], outputs=classifier, name='SiameseNetwork')\n",
    "\n",
    "    # Compile the model with a binary cross-entropy loss (since we are dealing with a similarity score)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Print the model summary\n",
    "    model.summary()\n",
    "\n",
    "    # Return the Siamese model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_img (InputLayer)         [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validation_img (InputLayer)    [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4096)         38960448    ['input_img[0][0]',              \n",
      "                                                                  'validation_img[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              (None, 4096)         0           ['embedding[0][0]',              \n",
      "                                                                  'embedding[1][0]']              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1)            4097        ['lambda_7[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model = make_siamese_model(base_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoints and early stopping\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "\n",
    "# Create checkpoint directory if it doesn't exist\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Create the checkpoint for saving the model and optimizer state\n",
    "checkpoint = tf.train.Checkpoint(optimizer=opt, siamese_model=siamese_model)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the Siamese Network\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m siamese_model\u001b[38;5;241m.\u001b[39mfit([\u001b[43mX_train_a\u001b[49m, X_train_b], \n\u001b[0;32m      3\u001b[0m                             y_train,\n\u001b[0;32m      4\u001b[0m                             batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m      5\u001b[0m                             epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,  \u001b[38;5;66;03m# Adjust the number of epochs as necessary\u001b[39;00m\n\u001b[0;32m      6\u001b[0m                             validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m      7\u001b[0m                             callbacks\u001b[38;5;241m=\u001b[39m[early_stopping])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Save the model and optimizer state after training\u001b[39;00m\n\u001b[0;32m     10\u001b[0m checkpoint\u001b[38;5;241m.\u001b[39msave(file_prefix\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mckpt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_a' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the Siamese Network\n",
    "history = siamese_model.fit([X_train_a, X_train_b], \n",
    "                            y_train,\n",
    "                            batch_size=16,\n",
    "                            epochs=50,  # Adjust the number of epochs as necessary\n",
    "                            validation_split=0.2,\n",
    "                            callbacks=[early_stopping])\n",
    "\n",
    "# Save the model and optimizer state after training\n",
    "checkpoint.save(file_prefix=os.path.join(checkpoint_dir, 'ckpt'))\n",
    "\n",
    "siamese_model.save('siamesemodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model using custom_objects with the Lambda function or K.abs directly\n",
    "siamese_model = tf.keras.models.load_model('siamesemodel.h5',\n",
    "    custom_objects={'<lambda>': Lambda(lambda tensors: K.abs(tensors[0] - tensors[1])), \n",
    "                    'BinaryCrossentropy': tf.losses.BinaryCrossentropy}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test data\n",
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next()\n",
    "y_hat = siamese_model.predict([test_input, test_val])\n",
    "\n",
    "# Post processing the results \n",
    "[1 if prediction > 0.5 else 0 for prediction in y_hat ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a metric object \n",
    "m = Recall()\n",
    "\n",
    "# Calculating the recall value \n",
    "m.update_state(y_true, y_hat)\n",
    "\n",
    "# Return Recall Result\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a metric object \n",
    "m = Precision()\n",
    "\n",
    "# Calculating the recall value \n",
    "m.update_state(y_true, y_hat)\n",
    "\n",
    "# Return Recall Result\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Recall()\n",
    "p = Precision()\n",
    "\n",
    "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
    "    yhat = siamese_model.predict([test_input, test_val])\n",
    "    r.update_state(y_true, yhat)\n",
    "    p.update_state(y_true,yhat) \n",
    "\n",
    "print(r.result().numpy(), p.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Recall()\n",
    "p = Precision()\n",
    "\n",
    "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
    "    yhat = siamese_model.predict([test_input, test_val])\n",
    "    r.update_state(y_true, yhat)\n",
    "    p.update_state(y_true,yhat) \n",
    "\n",
    "print(r.result().numpy(), p.result().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
